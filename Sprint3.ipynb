{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "UmdfWoy1vjN9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "import numpy as np  # import auxiliary library, typical idiom\n",
    "import pandas as pd  # import the Pandas library, typical idiom\n",
    "from pandas import read_csv\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "import pm4py\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  # for linear regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.cluster import KMeans  # for clustering\n",
    "from sklearn.tree import DecisionTreeClassifier  # for decision tree mining\n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.linear_model import HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "qwzwRVG_vhqh"
   },
   "outputs": [],
   "source": [
    "file_export = 'export2018.csv'\n",
    "data = pd.read_csv(file_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYVm3bvcETx5"
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_zL5ww6aO1w"
   },
   "source": [
    "Pre-processing\n",
    "* Visualization\n",
    "1. Unix time\n",
    "2. Encoding of categorical features\n",
    "3. Temporal ordering\n",
    "4. Aditional features:\n",
    "- Previous event\n",
    "- Next event\n",
    "- Day of the week\n",
    "- Time of day\n",
    "- Event duration\n",
    "5. Separate 80-20 \n",
    "- Visualization\n",
    "6. Get rid of overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Ce6x4-68AYCp"
   },
   "outputs": [],
   "source": [
    "data = data.sort_values(by=['case','startTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "UkLk7PX7CvL4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/696655479.py:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"calculator_nb\" failed type inference due to: \u001b[1mUntyped global name 'object':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'type'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\696655479.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/696655479.py:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"calculator_nb\" failed type inference due to: \u001b[1mUntyped global name 'object':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'type'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\696655479.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"calculator_nb\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\696655479.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\696655479.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/696655479.py:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"calculator_nb\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type array(pyobject, 1d, C)\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/696655479.py (6)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\696655479.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"calculator_nb\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\696655479.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\696655479.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    }
   ],
   "source": [
    "#Duration\n",
    "@jit(parallel = True)\n",
    "def calculator_nb(case, startTime):\n",
    "    res = np.empty(len(case), dtype=object)\n",
    "    idx = 0\n",
    "    for _ in case:\n",
    "        if (idx+1 >= len(case)):\n",
    "            break\n",
    "\n",
    "        if (case[idx + 1] == case[idx]):\n",
    "            res[idx] = startTime[idx + 1]\n",
    "        else:\n",
    "            res[idx] = startTime[idx]\n",
    "\n",
    "        idx+=1\n",
    "    return res\n",
    "\n",
    "data['completeTime'] = calculator_nb(data['case'].values, data['startTime'].values)\n",
    "data.at[317373, 'completeTime'] = data.at[317373, 'startTime']\n",
    "\n",
    "data['startTime'] =  pd.to_datetime(data['startTime'])\n",
    "data['completeTime'] =  pd.to_datetime(data['completeTime'])\n",
    "data['duration'] = data['completeTime'] - data['startTime']\n",
    "#to turn duration into seconds:\n",
    "duration = data['duration']\n",
    "duration = duration / np.timedelta64(1, 's')\n",
    "data['duration'] = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "qyyc-XNsAYCr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1360192189.py:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"calculator_nb\" failed type inference due to: \u001b[1mUntyped global name 'object':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'type'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1360192189.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1360192189.py:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"calculator_nb\" failed type inference due to: \u001b[1mUntyped global name 'object':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'type'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1360192189.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"calculator_nb\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1360192189.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1360192189.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1360192189.py:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"calculator_nb\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type array(pyobject, 1d, C)\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1360192189.py (6)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1360192189.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"calculator_nb\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1360192189.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1360192189.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    }
   ],
   "source": [
    "#Next event\n",
    "@jit(parallel = True)\n",
    "def calculator_nb(case, event):\n",
    "    res = np.empty(len(case), dtype=object)\n",
    "    idx = 0\n",
    "    for _ in case:\n",
    "        if (idx+1 >= len(case)):\n",
    "            break\n",
    "       \n",
    "        if (case[idx + 1] == case[idx]):\n",
    "            res[idx] = event[idx + 1]\n",
    "\n",
    "        idx+=1\n",
    "    return res\n",
    "\n",
    "data['next_event'] = calculator_nb(data['case'].values, data['event'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "VxseoX0JAYCr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1972138414.py:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"calculator_nb\" failed type inference due to: \u001b[1mUntyped global name 'object':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'type'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1972138414.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1972138414.py:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"calculator_nb\" failed type inference due to: \u001b[1mUntyped global name 'object':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'type'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1972138414.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"calculator_nb\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1972138414.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1972138414.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1972138414.py:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"calculator_nb\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type array(pyobject, 1d, C)\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1972138414.py (6)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1972138414.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"calculator_nb\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1972138414.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1972138414.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    }
   ],
   "source": [
    "#Previous event\n",
    "@jit(parallel = True)\n",
    "def calculator_nb(case, event):\n",
    "    res = np.empty(len(case), dtype=object)\n",
    "    idx = 0\n",
    "    for _ in case:\n",
    "        if (idx+1 >= len(case)):\n",
    "            break\n",
    "       \n",
    "        if (case[idx + 1] == case[idx]):\n",
    "            res[idx + 1] = event[idx]\n",
    "\n",
    "        idx+=1\n",
    "    return res\n",
    "\n",
    "data['prev_event'] = calculator_nb(data['case'].values, data['event'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "lseT5ybaAYCs"
   },
   "outputs": [],
   "source": [
    "#Removing null values\n",
    "data['next_event'] = data['next_event'].fillna(value='None')\n",
    "data['prev_event'] = data['prev_event'].fillna(value='None')\n",
    "data['note'] = data['note'].fillna(value='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "EK0yT10d4erc"
   },
   "outputs": [],
   "source": [
    "#unix time\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "data['startTime'] = pd.to_datetime(data['startTime'], dayfirst=True)\n",
    "unixTransform = lambda x: time.mktime(x.timetuple())\n",
    "data[\"UNIX_starttime\"] = data[\"startTime\"].apply(unixTransform).astype(int)\n",
    "\n",
    "data['completeTime'] = pd.to_datetime(data['completeTime'], dayfirst=True)\n",
    "unixTransform = lambda x: time.mktime(x.timetuple())\n",
    "data[\"UNIX_completeTime\"] = data[\"completeTime\"].apply(unixTransform).astype(int)\n",
    "\n",
    "#data['REG_DATE'] = pd.to_datetime(data['REG_DATE'], dayfirst=True)\n",
    "#unixTransform = lambda x: time.mktime(x.timetuple())\n",
    "#data[\"UNIX_REG_DATE\"] = data[\"REG_DATE\"].apply(unixTransform).astype(int)\n",
    "\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "7YGUvDZrAYCt"
   },
   "outputs": [],
   "source": [
    "#Day of the week\n",
    "data['weekday'] = data['startTime'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "78FN-5HNNi4f"
   },
   "outputs": [],
   "source": [
    "#encoding of categorical data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "6l7QS1P6ndTr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>event</th>\n",
       "      <th>startTime</th>\n",
       "      <th>completeTime</th>\n",
       "      <th>penalty_JLP1</th>\n",
       "      <th>penalty_JLP3</th>\n",
       "      <th>number_parcels</th>\n",
       "      <th>penalty_JLP2</th>\n",
       "      <th>penalty_JLP5</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>docid_uuid</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>success</th>\n",
       "      <th>duration</th>\n",
       "      <th>next_event</th>\n",
       "      <th>prev_event</th>\n",
       "      <th>UNIX_starttime</th>\n",
       "      <th>UNIX_completeTime</th>\n",
       "      <th>weekday</th>\n",
       "      <th>original index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>980452d16c80c2c3</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>2014-05-04 00:00:00.000</td>\n",
       "      <td>2015-04-24 00:00:00.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>93F2F9CA-6F07-4E87-8107-4852A7B1CBA2</td>\n",
       "      <td>0;n/a</td>\n",
       "      <td>True</td>\n",
       "      <td>30672000.000</td>\n",
       "      <td>mail income</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>1399154400</td>\n",
       "      <td>1429826400</td>\n",
       "      <td>6</td>\n",
       "      <td>63730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>980452d16c80c2c3</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>2014-05-04 00:00:00.000</td>\n",
       "      <td>2014-05-04 00:00:00.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>93F2F9CA-6F07-4E87-8107-4852A7B1CBA2</td>\n",
       "      <td>0;n/a</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>1399154400</td>\n",
       "      <td>1399154400</td>\n",
       "      <td>6</td>\n",
       "      <td>63729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cb3425ce193199d7</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>2014-05-04 00:00:00.000</td>\n",
       "      <td>2014-05-04 00:00:00.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>990E93F0-3BDD-464C-8102-F201E9F5EEE4</td>\n",
       "      <td>0;n/a</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>None</td>\n",
       "      <td>1399154400</td>\n",
       "      <td>1399154400</td>\n",
       "      <td>6</td>\n",
       "      <td>594649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>980452d16c80c2c3</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>2014-05-04 00:00:00.000</td>\n",
       "      <td>2014-05-04 00:00:00.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>2118A637-DCB0-4382-BC47-93BF0CF535AC</td>\n",
       "      <td>0;n/a</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>None</td>\n",
       "      <td>1399154400</td>\n",
       "      <td>1399154400</td>\n",
       "      <td>6</td>\n",
       "      <td>63727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cb3425ce193199d7</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>2014-05-04 00:00:00.000</td>\n",
       "      <td>2014-05-04 00:00:00.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>F94BE88D-511C-44B8-B2CE-988A147E7DF8</td>\n",
       "      <td>0;n/a</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>mail valid</td>\n",
       "      <td>1399154400</td>\n",
       "      <td>1399154400</td>\n",
       "      <td>6</td>\n",
       "      <td>594651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514261</th>\n",
       "      <td>8cd07a136f401349</td>\n",
       "      <td>calculate</td>\n",
       "      <td>2018-01-19 12:27:24.824</td>\n",
       "      <td>2018-01-19 12:27:24.824</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>D555F997-BDE0-471A-99AC-5CC0E1BD650F</td>\n",
       "      <td>75992a</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>None</td>\n",
       "      <td>begin editing</td>\n",
       "      <td>1516361244</td>\n",
       "      <td>1516361244</td>\n",
       "      <td>4</td>\n",
       "      <td>1020230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514262</th>\n",
       "      <td>dc56a531f5aeb3b0</td>\n",
       "      <td>save</td>\n",
       "      <td>2018-01-19 12:51:34.000</td>\n",
       "      <td>2018-01-19 12:51:34.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>49</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>24CD9E6F-6A0D-4C41-8D76-D3BE35B82681</td>\n",
       "      <td>8d8538</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>None</td>\n",
       "      <td>finish payment</td>\n",
       "      <td>1516362694</td>\n",
       "      <td>1516362694</td>\n",
       "      <td>4</td>\n",
       "      <td>1553199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514263</th>\n",
       "      <td>7b405bc5144c14c9</td>\n",
       "      <td>save</td>\n",
       "      <td>2018-01-19 12:57:05.000</td>\n",
       "      <td>2018-01-19 13:02:32.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>6EF39194-5730-4F6E-966C-C6B1D7A7DBC6</td>\n",
       "      <td>8d8538</td>\n",
       "      <td>True</td>\n",
       "      <td>327.000</td>\n",
       "      <td>save</td>\n",
       "      <td>finish payment</td>\n",
       "      <td>1516363025</td>\n",
       "      <td>1516363352</td>\n",
       "      <td>4</td>\n",
       "      <td>1189623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514264</th>\n",
       "      <td>7b405bc5144c14c9</td>\n",
       "      <td>save</td>\n",
       "      <td>2018-01-19 13:02:32.000</td>\n",
       "      <td>2018-01-19 13:02:32.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>6EF39194-5730-4F6E-966C-C6B1D7A7DBC6</td>\n",
       "      <td>8d8538</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>None</td>\n",
       "      <td>save</td>\n",
       "      <td>1516363352</td>\n",
       "      <td>1516363352</td>\n",
       "      <td>4</td>\n",
       "      <td>1189624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514265</th>\n",
       "      <td>4ae57656c3f23ff7</td>\n",
       "      <td>save</td>\n",
       "      <td>2018-01-19 13:03:02.000</td>\n",
       "      <td>2018-01-19 13:03:02.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>3D0BB1EE-ED99-4B57-B769-E1EBF7EF8A13</td>\n",
       "      <td>8d8538</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>None</td>\n",
       "      <td>calculate</td>\n",
       "      <td>1516363382</td>\n",
       "      <td>1516363382</td>\n",
       "      <td>4</td>\n",
       "      <td>1054460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2514266 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     case       event               startTime  \\\n",
       "0        980452d16c80c2c3  mail valid 2014-05-04 00:00:00.000   \n",
       "1        980452d16c80c2c3  mail valid 2014-05-04 00:00:00.000   \n",
       "2        cb3425ce193199d7  mail valid 2014-05-04 00:00:00.000   \n",
       "3        980452d16c80c2c3  mail valid 2014-05-04 00:00:00.000   \n",
       "4        cb3425ce193199d7  mail valid 2014-05-04 00:00:00.000   \n",
       "...                   ...         ...                     ...   \n",
       "2514261  8cd07a136f401349   calculate 2018-01-19 12:27:24.824   \n",
       "2514262  dc56a531f5aeb3b0        save 2018-01-19 12:51:34.000   \n",
       "2514263  7b405bc5144c14c9        save 2018-01-19 12:57:05.000   \n",
       "2514264  7b405bc5144c14c9        save 2018-01-19 13:02:32.000   \n",
       "2514265  4ae57656c3f23ff7        save 2018-01-19 13:03:02.000   \n",
       "\n",
       "                   completeTime  penalty_JLP1  penalty_JLP3  number_parcels  \\\n",
       "0       2015-04-24 00:00:00.000         False         False              32   \n",
       "1       2014-05-04 00:00:00.000         False         False              32   \n",
       "2       2014-05-04 00:00:00.000         False         False               5   \n",
       "3       2014-05-04 00:00:00.000         False         False              32   \n",
       "4       2014-05-04 00:00:00.000         False         False               5   \n",
       "...                         ...           ...           ...             ...   \n",
       "2514261 2018-01-19 12:27:24.824         False         False              37   \n",
       "2514262 2018-01-19 12:51:34.000         False         False              49   \n",
       "2514263 2018-01-19 13:02:32.000         False         False              43   \n",
       "2514264 2018-01-19 13:02:32.000         False         False              43   \n",
       "2514265 2018-01-19 13:03:02.000         False         False              31   \n",
       "\n",
       "         penalty_JLP2  penalty_JLP5  year  ...  \\\n",
       "0               False         False  2015  ...   \n",
       "1               False         False  2015  ...   \n",
       "2               False         False  2015  ...   \n",
       "3               False         False  2015  ...   \n",
       "4               False         False  2015  ...   \n",
       "...               ...           ...   ...  ...   \n",
       "2514261         False         False  2016  ...   \n",
       "2514262         False         False  2016  ...   \n",
       "2514263         False         False  2016  ...   \n",
       "2514264         False         False  2016  ...   \n",
       "2514265         False         False  2016  ...   \n",
       "\n",
       "                                   docid_uuid  org:resource  success  \\\n",
       "0        93F2F9CA-6F07-4E87-8107-4852A7B1CBA2         0;n/a     True   \n",
       "1        93F2F9CA-6F07-4E87-8107-4852A7B1CBA2         0;n/a     True   \n",
       "2        990E93F0-3BDD-464C-8102-F201E9F5EEE4         0;n/a     True   \n",
       "3        2118A637-DCB0-4382-BC47-93BF0CF535AC         0;n/a     True   \n",
       "4        F94BE88D-511C-44B8-B2CE-988A147E7DF8         0;n/a     True   \n",
       "...                                       ...           ...      ...   \n",
       "2514261  D555F997-BDE0-471A-99AC-5CC0E1BD650F        75992a     True   \n",
       "2514262  24CD9E6F-6A0D-4C41-8D76-D3BE35B82681        8d8538     True   \n",
       "2514263  6EF39194-5730-4F6E-966C-C6B1D7A7DBC6        8d8538     True   \n",
       "2514264  6EF39194-5730-4F6E-966C-C6B1D7A7DBC6        8d8538     True   \n",
       "2514265  3D0BB1EE-ED99-4B57-B769-E1EBF7EF8A13        8d8538     True   \n",
       "\n",
       "            duration   next_event      prev_event  UNIX_starttime  \\\n",
       "0       30672000.000  mail income      mail valid      1399154400   \n",
       "1              0.000   mail valid      mail valid      1399154400   \n",
       "2              0.000   mail valid            None      1399154400   \n",
       "3              0.000   mail valid            None      1399154400   \n",
       "4              0.000   mail valid      mail valid      1399154400   \n",
       "...              ...          ...             ...             ...   \n",
       "2514261        0.000         None   begin editing      1516361244   \n",
       "2514262        0.000         None  finish payment      1516362694   \n",
       "2514263      327.000         save  finish payment      1516363025   \n",
       "2514264        0.000         None            save      1516363352   \n",
       "2514265        0.000         None       calculate      1516363382   \n",
       "\n",
       "        UNIX_completeTime  weekday  original index  \n",
       "0              1429826400        6           63730  \n",
       "1              1399154400        6           63729  \n",
       "2              1399154400        6          594649  \n",
       "3              1399154400        6           63727  \n",
       "4              1399154400        6          594651  \n",
       "...                   ...      ...             ...  \n",
       "2514261        1516361244        4         1020230  \n",
       "2514262        1516362694        4         1553199  \n",
       "2514263        1516363352        4         1189623  \n",
       "2514264        1516363352        4         1189624  \n",
       "2514265        1516363382        4         1054460  \n",
       "\n",
       "[2514266 rows x 82 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensure we have acces to orignal indexing to keep track of the order of events in a process\n",
    "data['original index'] = data.index\n",
    "\n",
    "#sorting on time\n",
    "data.sort_values(by = \"UNIX_starttime\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "P5nloqg7KspI"
   },
   "outputs": [],
   "source": [
    "#separation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "YDODvtbAJZad"
   },
   "outputs": [],
   "source": [
    "#removing overlap - if case is in both datasets, remove\n",
    "\n",
    "train_cases = train['case'].unique().tolist()\n",
    "test_cases = test['case'].unique().tolist()\n",
    "\n",
    "intersect_list = list(set(train_cases).intersection(test_cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "T9a3TLae6Vgc"
   },
   "outputs": [],
   "source": [
    "#only removes first value in intersect list (needs modification for multiple overlaping values)\n",
    "\n",
    "#train = train[train['case'] != intersect_list[0]]\n",
    "#test = test[test['case'] != intersect_list[0]]\n",
    "\n",
    "#works for more values\n",
    "org_train = train[:10000].copy()\n",
    "org_test = test[:10000].copy()\n",
    "train = train[:10000]\n",
    "test = test[:10000]\n",
    "train=train.apply(label_encoder.fit_transform)\n",
    "test=test.apply(label_encoder.fit_transform)\n",
    "\n",
    "train = train[train['case'].isin(intersect_list) == False]\n",
    "X_train_time = train.drop(columns='duration')\n",
    "Y_train_time = train[\"duration\"]\n",
    "X_train_event = train.drop(columns=[\"next_event\"])\n",
    "Y_train_event = train[\"next_event\"]\n",
    "\n",
    "test = test[test['case'].isin(intersect_list) == False]\n",
    "X_test_time = test.drop(columns='duration')\n",
    "Y_test_time = test[\"duration\"]\n",
    "X_test_event = test.drop(columns=['next_event'])\n",
    "Y_test_event = test[\"next_event\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "fCxZL9hWDs33"
   },
   "outputs": [],
   "source": [
    "#separation visualisation\n",
    "\n",
    "# g = sns.scatterplot(x=\"UNIX_starttime\", y=\"case\", hue=\"enc_event\", data=data, palette='colorblind', legend=False)\n",
    "\n",
    "#add lines for separation - horizontal and vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "EJeqDuL6AYCv",
    "outputId": "60ac9040-5ca1-4e0c-c135-a0b9d38c39d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case', 'event', 'startTime', 'completeTime', 'penalty_JLP1',\n",
       "       'penalty_JLP3', 'number_parcels', 'penalty_JLP2', 'penalty_JLP5',\n",
       "       'year', 'penalty_JLP7', 'penalty_JLP6', 'redistribution',\n",
       "       'amount_applied1', 'amount_applied0', 'amount_applied3',\n",
       "       'amount_applied2', 'identity:id', 'penalty_V5', 'payment_actual0',\n",
       "       'payment_actual2', 'payment_actual1', 'penalty_B5F', 'payment_actual3',\n",
       "       'penalty_B16', 'penalty_GP1', 'basic payment', 'penalty_AGP', 'area',\n",
       "       'selected_manually', 'penalty_B3', 'penalty_B2', 'selected_risk',\n",
       "       'penalty_B5', 'penalty_AVBP', 'penalty_B4', 'penalty_B6', 'penalty_ABP',\n",
       "       'penalty_AVGP', 'penalty_C4', 'greening', 'rejected',\n",
       "       'cross_compliance', 'penalty_C9', 'penalty_AVJLP', 'penalty_CC',\n",
       "       'penalty_AVUVP', 'penalty_BGK', 'penalty_C16', 'penalty_BGP',\n",
       "       'department', 'small farmer', 'risk_factor', 'applicant',\n",
       "       'penalty_AUVP', 'penalty_amount2', 'penalty_BGKV', 'penalty_amount3',\n",
       "       'application', 'penalty_amount0', 'program-id', 'penalty_amount1',\n",
       "       'penalty_AJLP', 'selected_random', 'young farmer', 'note', 'eventid',\n",
       "       'activity', 'docid', 'subprocess', 'event_identity:id', 'doctype',\n",
       "       'docid_uuid', 'org:resource', 'success', 'duration', 'next_event',\n",
       "       'prev_event', 'UNIX_starttime', 'UNIX_completeTime', 'weekday',\n",
       "       'original index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9BgcNRxAYCw"
   },
   "source": [
    "# Feature prediction for time and event based on KBest(z-scores)\n",
    "note: don't run takes a significant time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "hPCfrgnjAYCw"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "def calc_feature_selection():\n",
    "    select = SelectKBest(k=10)  # takes best 10 arguments\n",
    "    z = select.fit_transform(X_train_time, Y_train_time)\n",
    "    filter = select.get_support()\n",
    "    print(np.extract(filter, X_train_time.columns))\n",
    "    #['event' 'year' 'penalty_AVBP' 'penalty_AVGP' 'eventid' 'activity' 'docid''subprocess' 'success' 'next_event']\n",
    "\n",
    "    select = SelectKBest(k=10)  # takes best 10 arguments\n",
    "    z = select.fit_transform(X_train_event, Y_train_event)\n",
    "    filter = select.get_support()\n",
    "    print(np.extract(filter, X_train_event.columns))\n",
    "    #['event' 'selected_random' 'note' 'eventid' 'activity' 'subprocess''doctype' 'org:resource' 'duration' 'prev_event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_feature_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnszwsuyCw71"
   },
   "source": [
    "# Naive Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive event (needs restructuring)\n",
    "data_baseline = org_test[[\"case\", \"event\", \"startTime\", \"completeTime\", \"next_event\", \"enc_event\", \"original index\"]].copy()\n",
    "#function to add column that keeps track of the position for each event per case\n",
    "@jit(parallel = True)\n",
    "def calculator_pos(case):\n",
    "    res = np.empty(len(case), dtype=object)\n",
    "    idx = 0\n",
    "    count=1\n",
    "    for _ in case:\n",
    "        if (idx+1 >= len(case)):\n",
    "            break\n",
    "        if (case[idx] == case[idx-1]):\n",
    "            count+=1\n",
    "            res[idx] = count          \n",
    "        else:\n",
    "            count=1\n",
    "            res[idx]=count\n",
    "        idx+=1\n",
    "    res[-1]=count+1\n",
    "    return res\n",
    "#get the position of each event per case\n",
    "data_baseline[\"pos\"] = calculator_pos(data_baseline['case'].to_numpy())\n",
    "#data_baseline = data_baseline[[\"case\", \"event\", \"startTime\", \"completeTime\", \"next_event\", \"enc_event\",  \"pos\", \"original index\"]].copy()\n",
    "\n",
    "#select most occuring event for each position \n",
    "#see https://stackoverflow.com/questions/15222754/groupby-pandas-dataframe-and-select-most-common-value\n",
    "events_count = data_baseline.groupby(\"pos\")['enc_event'].agg(lambda x: pd.Series.mode(x)[0]).to_frame()\n",
    "events_count = events_count.rename(columns={\"pos\":\"enc_event\"})\n",
    "#Next event for each position (most occuring event in the next position, e.g. 1-25, 2-26, so for 1 we predict 26)\n",
    "events_count['next_event2'] = events_count['enc_event'].shift(-1)\n",
    "events_count[\"next_event2\"].iloc[-1] = 0\n",
    "#map the model results to the original dataframe\n",
    "data_baseline[\"next_event2\"] = data_baseline[\"pos\"].map(events_count[\"next_event2\"])\n",
    "#Cleaning, set last events for each case to -1, so that we don't use them in final result and error estimation.\n",
    "data_baseline[\"index\"] = data_baseline.index\n",
    "#find last position for each case\n",
    "last_pos_per_case = data_baseline.groupby(\"case\")[[\"index\",\"case\",\"pos\"]].agg(max)\n",
    "#use index of the last event per case to assign -1 to the last event\n",
    "last_pos_per_case.set_index('index', inplace=True)\n",
    "#last_pos_per_case = last_pos_per_case[\"next_event2\"]\n",
    "data_baseline.loc[last_pos_per_case.index, \"next_event2\"] = -1\n",
    "#Basically, it is the final result of the naive event predictor on the train data\n",
    "#data_baseline.head(72)\n",
    "\n",
    "#Error measurement\n",
    "y_true = data_baseline[\"enc_event\"].to_numpy().astype(int)\n",
    "y_pred = data_baseline[\"next_event2\"].to_numpy().astype(int)\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_true, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the model on test dataset\n",
    "\n",
    "test_baseline = org_train[[\"case\", \"event\", \"startTime\", \"completeTime\", \"next_event\", \"enc_event\", \"original index\"]].copy()\n",
    "# get position column for the test dataset (required for the model to operate)\n",
    "test_baseline[\"pos\"] = calculator_pos(test_baseline['case'].to_numpy())\n",
    "#drop unnecessary stuff to speed up the process\n",
    "test_baseline = test_baseline[[\"case\", \"event\", \"startTime\", \"completeTime\", \"next_event\", \"enc_event\",  \"pos\", \"original index\"]].copy()\n",
    "#map the model results (obrained from train dataset) to the original dataframe\n",
    "test_baseline[\"next_event2\"] = test_baseline[\"pos\"].map(events_count[\"next_event2\"])\n",
    "\n",
    "#Cleaning, set last events for each case to -1, so that we don't use them in final result and error estimation.\n",
    "test_baseline[\"index\"] = test_baseline.index\n",
    "#find last position for each case\n",
    "last_pos_per_case = test_baseline.groupby(\"case\")[[\"index\",\"case\",\"pos\"]].agg(max)#.to_frame()\n",
    "#use index of the last event per case to assign -1 to the last event\n",
    "last_pos_per_case.set_index('index', inplace=True)\n",
    "#last_pos_per_case = last_pos_per_case[\"next_event2\"]\n",
    "test_baseline.loc[last_pos_per_case.index, \"next_event2\"] = -1\n",
    "#Basically, it is the final result of the naive event predictor on the test data\n",
    "test_baseline.head(72)\n",
    "\n",
    "#Error measurement\n",
    "y_true = test_baseline[\"enc_event\"].to_numpy().astype(int)\n",
    "y_pred = test_baseline[\"next_event2\"].to_numpy().astype(int)\n",
    "#y_true[-1] = 0\n",
    "#y_true, y_pred\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_true, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive time predictor (wasn't tested on test dataset, since I have no idea how to measure time accuracy)\n",
    "\n",
    "#find difference between completeTime of current event and the next event\n",
    "data_baseline[\"duration_start-start\"] = data_baseline[\"startTime\"].diff()\n",
    "#shift it up, so the difference corresponds to the current event\n",
    "data_baseline[\"duration_start-start\"] = data_baseline[\"duration_start-start\"].shift(-1)\n",
    "#set time duration between cases to NaT (last event per case, last position), since we only want time duration per case\n",
    "data_baseline.loc[ data_baseline[ data_baseline[\"next_event2\"] == -1 ].index, \"duration_start-start\"] = 'NaT'\n",
    "#find average time duration between startTime of the events at current position and at the next position\n",
    "predicted_duration = data_baseline.groupby(\"pos\")['duration_start-start'].agg('mean')\n",
    "#map the model results to the test dataset\n",
    "data_baseline[\"predicted_duration\"] = data_baseline['pos'].map(predicted_duration)\n",
    "#add predicted duration to completeTime to predict the startTime of the event in the next position\n",
    "data_baseline[\"predicted_time\"] = data_baseline[\"startTime\"] + data_baseline[\"predicted_duration\"]\n",
    "data_baseline = data_baseline.drop(['predicted_duration', 'duration_start-start'], axis=1)\n",
    "#data_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous naive predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "RIsCchagAYCx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1978921505.py:4: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"calculator_pos\" failed type inference due to: \u001b[1mUntyped global name 'object':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'type'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1978921505.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1978921505.py:4: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"calculator_pos\" failed type inference due to: \u001b[1mUntyped global name 'object':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'type'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1978921505.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"calculator_pos\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1978921505.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1978921505.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1978921505.py:4: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"calculator_pos\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type array(pyobject, 1d, C)\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\chbak\\AppData\\Local\\Temp/ipykernel_5376/1978921505.py (9)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1978921505.py\", line 9:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"calculator_pos\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1978921505.py\", line 9:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Python310\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\AppData\\Local\\Temp\\ipykernel_5376\\1978921505.py\", line 9:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6982: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "# Naive event (needs restructuring)\n",
    "data_baseline= test.copy()\n",
    "\n",
    "@jit(parallel = True)\n",
    "def calculator_pos(case):\n",
    "    res = np.empty(len(case), dtype=object)\n",
    "    idx = 0\n",
    "    count=1\n",
    "    for _ in case:\n",
    "        if (idx+1 >= len(case)):\n",
    "            break\n",
    "       \n",
    "        if (case[idx] == case[idx-1]):\n",
    "            count+=1\n",
    "            res[idx] = count\n",
    "            \n",
    "        else:\n",
    "            count=1\n",
    "            res[idx]=count\n",
    "\n",
    "        idx+=1\n",
    "    res[-1]=count+1\n",
    "    return res\n",
    "\n",
    "data_baseline[\"pos\"] = calculator_pos(data_baseline['case'].values)\n",
    "\n",
    "event_to_num = {}\n",
    "list_of_events = train[\"event\"].unique()\n",
    "i=0\n",
    "for event in list_of_events:\n",
    "    event_to_num[str(event)] = i\n",
    "    i += 1\n",
    "event_to_num['None'] = i\n",
    "\n",
    "pop=data_baseline.sort_values(by='pos')\n",
    "pop['eventnum']=pop['event']\n",
    "pop2=pop.set_index('pos')\n",
    "pop3=pop[['pos','eventnum']]\n",
    "pop4=pop3.groupby(['pos', 'eventnum']).apply(pd.DataFrame.mode).reset_index(drop=True)\n",
    "pop5=pop4.drop_duplicates(subset='pos')\n",
    "ptenum= dict(zip(pop5.pos, pop5.eventnum))\n",
    "num_to_event = {value:key for key, value in event_to_num.items()}\n",
    "data_baseline['predicted_event_num'] = (data_baseline['pos']+1).map(ptenum)\n",
    "data_baseline['predicted_event'] = (data_baseline['predicted_event_num']).map(num_to_event)\n",
    "data_baseline_final=data_baseline.drop(['predicted_event_num'],axis=1)\n",
    "\n",
    "next_task=[]\n",
    "predicted_event=[]\n",
    "for event in data_baseline_final['next_event']:\n",
    "    next_task.append(str(event))\n",
    "    \n",
    "\n",
    "for case in data_baseline_final['predicted_event']:\n",
    "    predicted_event.append(str(case))\n",
    "\n",
    "accuracy_score(next_task,predicted_event)\n",
    "\n",
    "\n",
    "test[\"naive_event\"] = predicted_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "RXmI8N5fAYCx"
   },
   "outputs": [],
   "source": [
    "# Naive time\n",
    "#Sums up count for each event and the time each event takes\n",
    "events_count = train.groupby(\"event\")['duration'].agg('count')\n",
    "event_duration_sum = train.groupby(\"event\")['duration'].agg('sum')\n",
    "\n",
    "#Computes average duration per event (basically our trained data that can be mapped onto test data)\n",
    "duration_per_event = event_duration_sum / events_count \n",
    "\n",
    "test[\"naive_time\"] = test['event'].map(duration_per_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzkbO8ioDJXG"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def event_metrics(y_test, y_pred, avg=\"weighted\", model=\"...\"):\n",
    " \n",
    "    prec_score = precision_score(y_test, y_pred, average=avg, zero_division=0)\n",
    "    rec_score = recall_score(y_test, y_pred, average=avg, zero_division=0)\n",
    "    F1_score = f1_score(y_test, y_pred, average=avg, zero_division=0)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"Error metrics for the {model} event model\")\n",
    "    print(\"\\n\")\n",
    "    print(f'The accuracy of the model is {acc_score}.')\n",
    "    print(f'The precision of the model is {prec_score}, using {avg} average.')\n",
    "    print(f'The recall of the model is {rec_score}, using {avg} average.')\n",
    "    print(f'The f1-score of the model is {F1_score}, using {avg} average.')\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return acc_score, prec_score, rec_score, F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "bXp-EEClAYCy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Error metrics for the Random Forest event model\n",
      "\n",
      "\n",
      "The accuracy of the model is 0.3032.\n",
      "The precision of the model is 0.3467355006100965, using weighted average.\n",
      "The recall of the model is 0.3032, using weighted average.\n",
      "The f1-score of the model is 0.3146013246570676, using weighted average.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calc_random_forest():\n",
    "    # Create the random grid\n",
    "\n",
    "    RF = RandomForestClassifier(n_estimators=300,\n",
    "                                min_samples_split=10,\n",
    "                                min_samples_leaf=2,\n",
    "                                max_features='sqrt',\n",
    "                                max_depth=50,\n",
    "                                bootstrap=True)\n",
    "\n",
    "    dataset_col = [\n",
    "        'event',\n",
    "        'selected_random',\n",
    "        'subprocess',\n",
    "        'org:resource',\n",
    "        'duration',\n",
    "        'prev_event',\n",
    "    ]\n",
    "\n",
    "    RF_fit = RF.fit(X_train_event.filter(items=dataset_col), Y_train_event)\n",
    "    RF_pred = RF_fit.predict(X_test_event.filter(items=dataset_col))\n",
    "    # org_test[\"event_RF\"] = RF_pred\n",
    "    event_metrics(Y_test_event, RF_pred, model=\"Random Forest\") #91% accuracy on testing\n",
    "\n",
    "calc_random_forest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJ95WWv1FFq2"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "cEjA1xPPAYCz"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def time_metrics(y_test, y_pred, model=\"...\"):\n",
    "  \n",
    "    print(\"\\n\")\n",
    "    print(f\"Error metrics for the {model} time model\")\n",
    "    print(\"\\n\")\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print('$R_2$ score:', r2_score(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "SxFBpvJrAYC0",
    "outputId": "afef450d-4463-4567-a3a0-8f40a49df81a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 3s 17ms/step - loss: 3311444164608.0000\n",
      "313/313 [==============================] - 2s 5ms/step\n",
      "\n",
      "\n",
      "Error metrics for the LSTM time model\n",
      "\n",
      "\n",
      "Mean Absolute Error: 524297.3315508114\n",
      "Mean Squared Error: 3884620811392.472\n",
      "Root Mean Squared Error: 1970944.1421289626\n",
      "$R_2$ score: -0.07615180404045385\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calc_LSTM():\n",
    "    listVal = train\n",
    "    columnNames = [\n",
    "        'event', 'penalty_AVBP', 'penalty_AVGP', 'eventid', 'activity',\n",
    "        'docid', 'subprocess', 'success', 'next_event'\n",
    "    ]\n",
    "    listValSelected = listVal[columnNames]\n",
    "    listValSelected_prediction = test[columnNames]\n",
    "    listValSelected_prediction = listValSelected_prediction.values\n",
    "    listValDuration_prediction = org_test['duration']\n",
    "    listValDuration_prediction = listValDuration_prediction.values\n",
    "    listValDuration = org_train['duration'].values\n",
    "\n",
    "    listValSelected = listValSelected.values\n",
    "    n_steps = len(listValSelected[0])\n",
    "    # split into samples\n",
    "    n_features = 1\n",
    "    X = listValSelected.reshape(\n",
    "        (listValSelected.shape[0], listValSelected.shape[1], n_features))\n",
    "    y = listValDuration\n",
    "\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            100,\n",
    "            input_shape=(n_steps, n_features),\n",
    "            #  stateful=True,\n",
    "            return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(units=100))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(units=1))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    model.fit(X,\n",
    "              y,\n",
    "              batch_size=100,\n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              workers=-1,\n",
    "              use_multiprocessing=True)\n",
    "\n",
    "    # demonstrate prediction\n",
    "    x_input = listValSelected_prediction\n",
    "\n",
    "    x_input = x_input.reshape((x_input.shape[0], n_steps, n_features))\n",
    "    yhat = model.predict(x_input, verbose=1, use_multiprocessing=True)\n",
    "    org_test[\"time_LSTM\"] = yhat.flatten()[:len(listValDuration_prediction)]\n",
    "    time_metrics(listValDuration_prediction, yhat.flatten()[:len(listValDuration_prediction)], \"LSTM\")\n",
    "calc_LSTM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8VnfD11COk3"
   },
   "source": [
    "<h1>Neural network</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "4mAQfBJXA5e4"
   },
   "outputs": [],
   "source": [
    "def normalize(df_name, col_name):\n",
    "    col_as_array = df_name[col_name].to_numpy()\n",
    "    col_as_array = np.where(col_as_array == 0, 0.01, col_as_array)\n",
    "    col_as_array_norm = np.log10(col_as_array)\n",
    "    mean = col_as_array_norm.mean()\n",
    "    stdev = col_as_array_norm.std()\n",
    "    epsilon = 0.01\n",
    "    return (col_as_array_norm - mean) / (stdev + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "gjaBr85RBK9u"
   },
   "outputs": [],
   "source": [
    "def prepfeatures(df_name):\n",
    "    event = df_name['event'].to_numpy()\n",
    "    event = event.reshape(-1,1)\n",
    "    event = ordinal_encoder.fit_transform(event)\n",
    "    \n",
    "    #selected_random = df_name['selected_random'].to_numpy()\n",
    "    #selected_random = selected_random.reshape(-1,1)\n",
    "    #selected_random = ordinal_encoder.fit_transform(selected_random)\n",
    "    \n",
    "    #note = df_name['note'].to_numpy()\n",
    "    #note = note.reshape(-1,1)\n",
    "    #note = ordinal_encoder.fit_transform(note)\n",
    "    \n",
    "    #eventid = org_train['eventid'].to_numpy()\n",
    "    #eventid = eventid + abs(org_train['eventid'].min())\n",
    "    \n",
    "    #subprocess = df_name['subprocess'].to_numpy()\n",
    "    #subprocess = subprocess.reshape(-1,1)\n",
    "    #subprocess = ordinal_encoder.fit_transform(subprocess)\n",
    "    \n",
    "    #doctype = df_name['doctype'].to_numpy()\n",
    "    #doctype = doctype.reshape(-1,1)\n",
    "    #doctype = ordinal_encoder.fit_transform(doctype)\n",
    "    \n",
    "    duration = normalize(df_name,'duration')\n",
    "    weekday = df_name['weekday'].to_numpy()\n",
    "    \n",
    "    #startTime = normalize(df_name,'UNIX_starttime')\n",
    "    \n",
    "    prev_event = df_name['prev_event'].to_numpy()\n",
    "    prev_event = prev_event.reshape(-1,1)\n",
    "    prev_event = ordinal_encoder.fit_transform(prev_event)\n",
    "    \n",
    "    features = []\n",
    "    for i in range(len(event)):\n",
    "        current = event[i]\n",
    "        #current = np.append(current,selected_random[i])\n",
    "        #current = np.append(current,note[i])\n",
    "        #current = np.append(current,eventid[i])\n",
    "        #current = np.append(current,subprocess[i])\n",
    "        #current = np.append(current,doctype[i])\n",
    "        current = np.append(current,duration[i])\n",
    "        current = np.append(current,weekday[i])\n",
    "        #current = np.append(current,startTime[i])\n",
    "        current = np.append(current,prev_event[i])\n",
    "        features.append(current)\n",
    "        \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "OtJzg5ZPBNhL"
   },
   "outputs": [],
   "source": [
    "def preplabels(df_name):\n",
    "    labels = df_name['next_event'].to_numpy()\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    \n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "szrad1aBBRNR"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(4,)),\n",
    "    keras.layers.Dense(20, activation='softplus'),\n",
    "    keras.layers.Dropout(1/10),\n",
    "    keras.layers.Dense(30, activation='softplus'),\n",
    "    keras.layers.Dropout(1/15),\n",
    "    keras.layers.Dense(42, activation='softplus')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "def crossvalidation(k):\n",
    "    quantile = int(np.floor(len(data)/5))\n",
    "    for i in range(1,k-1):\n",
    "        train = data[:(quantile*i)]\n",
    "        train = train.sample(frac=1)\n",
    "        test = data[(quantile*i):(quantile*(i+1))]\n",
    "        \n",
    "        features = prepfeatures(train)\n",
    "        labels = preplabels(train)\n",
    "        \n",
    "        print(\"Training on 0:\",(quantile*i),\"; Testing on \",(quantile*i),\":\",(quantile*(i+1)))\n",
    "        model.fit(features,labels,epochs=3,verbose=1)\n",
    "        \n",
    "        features_test = prepfeatures(test)\n",
    "        labels_test = preplabels(test)\n",
    "        \n",
    "        eval = model.evaluate(features_test,labels_test)\n",
    "        losses.append(eval[0])\n",
    "        accuracies.append(eval[1])\n",
    "        \n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 0: 2000 ; Testing on  2000 : 4000\n",
      "Epoch 1/3\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.8545 - accuracy: 0.0640\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6546 - accuracy: 0.2185\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2860 - accuracy: 0.3600\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.2573 - accuracy: 0.0040\n",
      "Training on 0: 4000 ; Testing on  4000 : 6000\n",
      "Epoch 1/3\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 3.1395 - accuracy: 0.2295\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.3880 - accuracy: 0.3077\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.2694 - accuracy: 0.3380\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.8526 - accuracy: 0.0025\n",
      "Training on 0: 6000 ; Testing on  6000 : 8000\n",
      "Epoch 1/3\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 2.4072 - accuracy: 0.2268\n",
      "Epoch 2/3\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 2.0792 - accuracy: 0.2835\n",
      "Epoch 3/3\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.9888 - accuracy: 0.3372\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5893 - accuracy: 0.0285\n"
     ]
    }
   ],
   "source": [
    "losses, accuracies = crossvalidation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011666666716337204"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(accuracies).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data = prepfeatures(data)\n",
    "prediction = model.predict(features_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_events = []\n",
    "for i in range(len(prediction)):\n",
    "    predicted_events.append(np.argmax(prediction[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_events = label_encoder.inverse_transform(predicted_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['neuralnet_event_prediction'] = predicted_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMwKREQNFNMU"
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "ujVonZkbFUFB"
   },
   "outputs": [],
   "source": [
    "def prepfeatures_regression(df_name):\n",
    "    event = df_name['event'].to_numpy()\n",
    "    event = event.reshape(-1,1)\n",
    "    event = ordinal_encoder.fit_transform(event)\n",
    "    \n",
    "    next_event = df_name['next_event'].to_numpy()\n",
    "    next_event = next_event.reshape(-1,1)\n",
    "    next_event = ordinal_encoder.fit_transform(next_event)\n",
    "    \n",
    "    year = df_name['year'].to_numpy()\n",
    "    year = year.reshape(-1,1)\n",
    "    year = ordinal_encoder.fit_transform(year)\n",
    "    \n",
    "    penalty_AVBP = df_name['penalty_AVBP'].to_numpy()\n",
    "    penalty_AVBP = penalty_AVBP.reshape(-1,1)\n",
    "    penalty_AVBP = ordinal_encoder.fit_transform(penalty_AVBP)\n",
    "    \n",
    "    penalty_AVGP = df_name['penalty_AVGP'].to_numpy()\n",
    "    penalty_AVGP = penalty_AVGP.reshape(-1,1)\n",
    "    penalty_AVGP = ordinal_encoder.fit_transform(penalty_AVGP)\n",
    "    \n",
    "    success = df_name['success'].to_numpy()\n",
    "    success = success.reshape(-1,1)\n",
    "    success = ordinal_encoder.fit_transform(success)\n",
    "    \n",
    "    eventid = df_name['eventid'].to_numpy()\n",
    "    eventid = success.reshape(-1,1)\n",
    "    \n",
    "    docid = df_name['docid'].to_numpy()\n",
    "    docid = success.reshape(-1,1)\n",
    "    \n",
    "    subprocess = df_name['subprocess'].to_numpy()\n",
    "    subprocess = subprocess.reshape(-1,1)\n",
    "    subprocess = ordinal_encoder.fit_transform(subprocess)\n",
    "    \n",
    "    weekday = df_name['weekday'].to_numpy()\n",
    "    weekday = weekday.reshape(-1,1)\n",
    "    \n",
    "    X = []\n",
    "    for i in range(len(event)):\n",
    "        current = event[i]\n",
    "        current = np.append(current, year[i])\n",
    "        current = np.append(current, penalty_AVBP[i])\n",
    "        current = np.append(current, penalty_AVGP[i])\n",
    "        current = np.append(current, success[i])\n",
    "        current = np.append(current, eventid[i])\n",
    "        current = np.append(current, docid[i])\n",
    "        current = np.append(current, next_event[i])\n",
    "        current = np.append(current, subprocess[i])\n",
    "        current = np.append(current, weekday[i])\n",
    "        X.append(current)\n",
    "        \n",
    "    return np.array(X, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "Y_VXHw5DFaAI"
   },
   "outputs": [],
   "source": [
    "def preplabels_regression(df_name):\n",
    "    duration = df_name['duration'].to_numpy()\n",
    "    return np.array(duration, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prepfeatures_regression(org_train)\n",
    "y = preplabels_regression(org_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "M0Qh176sFcMT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2086.232180857761"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber = HuberRegressor().fit(X, y)\n",
    "\n",
    "X_test = prepfeatures_regression(org_test)\n",
    "\n",
    "org_test['regression_duration'] = huber.predict(X_test)\n",
    "org_test['error'] = np.absolute(org_test['duration'] - org_test['regression_duration'])\n",
    "org_test['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_prediction = prepfeatures_regression(data)\n",
    "data['regression_time_prediction'] = huber.predict(X_for_prediction)\n",
    "data['regression_time_prediction'] = data['regression_time_prediction'] + data['UNIX_starttime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['regression_time_predicition'] = data['regression_time_prediction'].apply(datetime.fromtimestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sprint3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

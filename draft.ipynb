{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5c7aaecf2980>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from numba import jit\n",
    "from sklearn.linear_model import LinearRegression  # for linear regression\n",
    "from sklearn.tree import DecisionTreeClassifier  # for decision tree mining\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.8.0-cp37-cp37m-win_amd64.whl (437.9 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (45.2.0.post20200210)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.24.0)\n",
      "Collecting numpy>=1.20\n",
      "  Using cached numpy-1.21.5-cp37-cp37m-win_amd64.whl (14.0 MB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Processing c:\\users\\20201158\\appdata\\local\\pip\\cache\\wheels\\3f\\e3\\ec\\8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\\termcolor-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.44.0-cp37-cp37m-win_amd64.whl (3.4 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.22.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "Collecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
      "  Using cached importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.25.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (2.2.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Installing collected packages: absl-py, astunparse, google-pasta, libclang, numpy, tensorboard-data-server, importlib-metadata, markdown, grpcio, tensorboard-plugin-wit, oauthlib, requests-oauthlib, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, google-auth-oauthlib, tensorboard, termcolor, opt-einsum, keras-preprocessing, tf-estimator-nightly, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.1\n",
      "    Uninstalling numpy-1.18.1:\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "ERROR: pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\numpy\\\\compat\\\\py3k.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export = 'export2012.csv'\n",
    "data = pd.read_csv(file_export)\n",
    "df_sorted= data.sort_values(by=['case', 'startTime'])\n",
    "data = df_sorted.copy().loc[:,['case', 'event', 'startTime', 'completeTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted = data.sort_values(by=['case', 'event','completeTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterrated = data.copy()\n",
    "\n",
    "@jit(parallel = True)\n",
    "def calculator_nb(case, event):\n",
    "    res = np.empty(len(case), dtype=object)\n",
    "    idx = 0\n",
    "    for _ in case:\n",
    "        if (idx+1 >= len(case)):\n",
    "            break\n",
    "       \n",
    "        if (case[idx + 1] == case[idx]):\n",
    "            res[idx] = event[idx + 1]\n",
    "        idx+=1\n",
    "    return res\n",
    "\n",
    "data_iterrated[\"next_task\"] = calculator_nb(data_iterrated['case'].values, data_iterrated[\"event\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data_iterrated,test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterrated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_events = data_iterrated[\"event\"].unique()\n",
    "event_to_num = {}\n",
    "i=0\n",
    "for event in list_of_events:\n",
    "    event_to_num[str(event)] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_to_num['None'] = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive predictor. First, event predictor is constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each event, counts how many times another event occurs after it.\n",
    "#Indexed based on list_of_events\n",
    "count = {}\n",
    "# initialise the count dictionary with zeros, otherwise it does not work\n",
    "for event in list_of_events:\n",
    "        count[str(event)] = [0 for i in range(len(list_of_events))]\n",
    " \n",
    "\n",
    "for event in list_of_events:\n",
    "    for k in range(len(list_of_events)):\n",
    "        count[str(event)][k] = data_train[ (data_train['event'] == event) & (data_train['next_task'] == list_of_events[k]) ].count()['event']\n",
    "            \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The main part of the naive predictor\n",
    "#Takes the above dictionary and finds the most frequenly occuring consecutive\n",
    "#event after each event\n",
    "#Basically, it is our trained model that can be mapped to the original dataset\n",
    "count2 = count\n",
    "index = {}\n",
    "for event in list_of_events:\n",
    "    max = 0\n",
    "    for k in range( len(list_of_events)-1 ):\n",
    "        if count2[event][k] > max:\n",
    "            max = count2[event][k]\n",
    "            #print(max)\n",
    "            index2 = k\n",
    "    index[event] = index2\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turns the above into an event to event dictionary \n",
    "\n",
    "prediction = {}\n",
    "for event in list_of_events:\n",
    "    prediction[event] = list_of_events[index[event]]\n",
    "    \n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds predicted event column\n",
    "df_predicted_event = data_test.copy()\n",
    "df_predicted_event[\"predicted_event\"] = [\"\" for i in df_predicted_event[\"event\"]]\n",
    "df_predicted_event['predicted_event'] = df_predicted_event[\"event\"].map(prediction)\n",
    "df_predicted_event.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new3 = df_predicted_event.copy()\n",
    "df_new3[\"next_task\"] = df_new3[\"next_task\"].map(event_to_num)\n",
    "df_new3[\"predicted_event\"] = df_new3[\"predicted_event\"].map(event_to_num)\n",
    "df_new3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df_new3[\"next_task\"].to_numpy().astype(int)\n",
    "y_pred = df_new3[\"predicted_event\"].to_numpy().astype(int)\n",
    "y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive time predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted_time = data_train.copy()\n",
    "df_predicted_time[\"duration\"] = pd.to_datetime(df_predicted_time[\"completeTime\"]) - pd.to_datetime(df_predicted_time[\"startTime\"])\n",
    "\n",
    "#Sums up count for each event and the time each event takes\n",
    "events_count = df_predicted_time.groupby(\"event\")['duration'].agg('count')\n",
    "event_duration_sum = df_predicted_time.groupby(\"event\")['duration'].agg('sum')\n",
    "\n",
    "#Computes average duration per event (basically our trained data that can be mapped onto test data)\n",
    "duration_per_event = event_duration_sum / events_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final cleanup\n",
    "df_predicted = df_predicted_event.copy()\n",
    "df_predicted[\"predicted_duration\"] = df_predicted['event'].map(duration_per_event)\n",
    "df_predicted = df_predicted.drop(['next_task'], axis=1)\n",
    "df_predicted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding predicted start time of next event\n",
    "df_predicted_final = df_predicted.copy()\n",
    "df_predicted_final['predicted_time'] = df_predicted_final[\"predicted_duration\"] + pd.to_datetime(df_predicted_final[\"startTime\"])\n",
    "df_predicted_final.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterrated_two = data_iterrated[\"event\"].copy()\n",
    "data_iterrated_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_iterrated_two)):\n",
    "    data_iterrated_two[i] = event_to_num[data_iterrated_two[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_task = data_iterrated[\"next_task\"].copy()\n",
    "for i in range(len(next_task)):\n",
    "    try:\n",
    "        next_task[i] = event_to_num[next_task[i]]\n",
    "    except:\n",
    "        next_task[i] = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_lr = data_iterrated.copy()\n",
    "data_to_lr[\"event\"] = data_iterrated_two\n",
    "data_to_lr[\"next_task\"] = next_task\n",
    "data_to_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_to_lr[[\"event\"]]\n",
    "y = data_to_lr[\"next_task\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "naive_predictor = LinearRegression()\n",
    "naive_predictor.fit(X_train, y_train)\n",
    "naive_predictor.score(X_test, y_test)\n",
    "prediction = naive_predictor.predict(data_to_lr[[\"event\"]]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = data_to_lr.copy()\n",
    "result_data[\"prediction\"] = prediction\n",
    "result_data[\"prediction\"] = result_data[\"prediction\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_event = {v: k for k, v in event_to_num.items()}\n",
    "num_to_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_event_str = result_data[\"prediction\"].copy()\n",
    "for i in range(len(predicted_event_str)):\n",
    "    predicted_event_str[i] = num_to_event[predicted_event_str[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_event_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_str = data_iterrated.copy()\n",
    "result_data_str[\"prediction\"] = predicted_event_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_str[\"duration\"] = pd.to_datetime(result_data_str[\"completeTime\"]) - pd.to_datetime(result_data_str[\"startTime\"])\n",
    "result_data_str.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "events_count = result_data_str.groupby(\"event\")['duration'].agg('count')\n",
    "event_duration_sum = result_data_str.groupby(\"event\")['duration'].agg('sum')\n",
    "\n",
    "duration_per_event = event_duration_sum / events_count\n",
    "\n",
    "@jit(parallel = True)\n",
    "def make_prediction(event, dict):\n",
    "    res = np.empty(len(event), dtype=object)\n",
    "    for idx,_ in enumerate(event):    \n",
    "        res[idx] = dict[event[idx]]\n",
    "    return res\n",
    "\n",
    "result_data_str[\"duration_prediction\"] = make_prediction(result_data_str['event'].values, duration_per_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_str.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More advanced algorithms (from Hristo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = result_data[result_data[\"case\"] < len(result_data)]\n",
    "df_prediction = result_data[result_data[\"case\"] >= len(result_data)][:100]\n",
    "\n",
    "df_filtered=df_filtered.dropna() #Check later if dropna messes with the dataset through \"None\" tasks being interpreted as NaN\n",
    "df_prediction=df_prediction.dropna()\n",
    "df_filtered[\"startTime\"] = pd.to_datetime(df_filtered[\"startTime\"])\n",
    "df_prediction[\"startTime\"] = pd.to_datetime(df_prediction[\"startTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLS regression\n",
    "import statsmodels.api as sm\n",
    "df_filtered = result_data[result_data[\"case\"] < len(result_data)]\n",
    "df_prediction = result_data[result_data[\"case\"] >= len(result_data)]\n",
    "\n",
    "\n",
    "df_filtered=df_filtered.dropna()\n",
    "df_prediction=df_prediction.dropna()\n",
    "df_filtered[\"startTime\"] = pd.to_datetime(df_filtered[\"startTime\"])\n",
    "df_prediction[\"startTime\"] = pd.to_datetime(df_prediction[\"startTime\"])\n",
    "\n",
    "y = np.array(pd.to_numeric(df_filtered[\"startTime\"].values), dtype=float)\n",
    "X = np.array(df_filtered[\"event\"].values, dtype=float)\n",
    "olsmod = sm.OLS(y, X)\n",
    "olsres = olsmod.fit()\n",
    "ypred = olsres.predict(X)\n",
    "Xnew = np.array(df_prediction[\"event\"].values, dtype=float)\n",
    "ynewpred = olsres.predict(Xnew) \n",
    "df_prediction[\"time_OLS\"] = pd.to_datetime(ynewpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "y = np.floor(pd.to_numeric(df_filtered[\"startTime\"].values), dtype=float)\n",
    "X = df_filtered[[\"event\", \"case\"]]\n",
    "\n",
    "lassoReg = linear_model.Lasso()\n",
    "lassoReg.fit(X, y)\n",
    "\n",
    "Xnew = np.array(df_prediction[[\"event\", \"case\"]].values, dtype=float)\n",
    "df_prediction[\"time_Lasso\"] = pd.to_datetime(lassoReg.predict(Xnew))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Fores and Decision Tree for event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data\n",
    "result_data.sort_values(by=[\"case\", \"event\"], inplace=True)\n",
    "result_data_copy = result_data.copy()\n",
    "result_data_copy['startTime'] = pd.to_numeric(pd.to_datetime(result_data_copy['startTime']))\n",
    "result_data_copy['completeTime'] = pd.to_numeric(pd.to_datetime(result_data_copy['completeTime']))\n",
    "result_data_copy['REG_DATE'] = pd.to_numeric(pd.to_datetime(result_data_copy['REG_DATE']))\n",
    "result_data_copy.drop(columns='prediction', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test and ensure floating point numbers\n",
    "X = result_data_copy.drop(['next_task'], axis=1)\n",
    "y = result_data_copy['next_task']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "event_columns = X_train.columns\n",
    "X_train = X_train.values.astype(\"float32\")\n",
    "y_train = y_train.values.astype(\"float32\")\n",
    "X_test = X_test.values.astype(\"float32\")\n",
    "y_test = y_test.values.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting and prediction \n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_model = SelectFromModel(DT_fit, prefit=True)\n",
    "X_new = DT_model.transform(X)\n",
    "#X_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_df = pd.DataFrame(X_new, columns= [\"event\", \"startTime\", \"completeTime\"])\n",
    "X_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "DT_pred = np.round(DT_pred)\n",
    "RF_pred = np.round(RF_pred)\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to df\n",
    "test_df[\"event_DT\"] = DT_pred\n",
    "test_df[\"event_RF\"] = RF_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y\n",
    "\n",
    "X_n_train, X_n_test, y_n_train, y_n_test = train_test_split(X_new_df, y)\n",
    "event_columns = X_n_train.columns\n",
    "X_n_train = X_n_train.values.astype(\"float32\")\n",
    "y_n_train = y_n_train.values.astype(\"float32\")\n",
    "X_n_test = X_n_test.values.astype(\"float32\")\n",
    "y_n_test = y_n_test.values.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_n_fit = DT.fit(X_n_train, y_n_train)\n",
    "DT_n_pred = DT_fit.predict(X_n_test)\n",
    "DT_n_pred = np.round(DT_n_pred)\n",
    "print(\"Decision Trees with feature selection is %f percent accurate\" % (accuracy_score(DT_n_pred, Y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM for time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = result_data.sort_values(by=[\"case\", \"event\"])\n",
    "\n",
    "df_result[\"duration\"] = pd.to_numeric(pd.to_datetime(df_result[\"completeTime\"]) - pd.to_datetime(df_result[\"startTime\"]))\n",
    "df_result['REG_DATE'] = pd.to_numeric(pd.to_datetime(df_result['REG_DATE']))\n",
    "df_result['completeTime'] = pd.to_numeric(pd.to_datetime(df_result['completeTime']))\n",
    "df_result['startTime'] = pd.to_numeric(pd.to_datetime(df_result['startTime']))\n",
    "\n",
    "df_filtered = df_result[df_result[\"case\"] < len(df_result)]\n",
    "df_prediction = df_result[df_result[\"case\"] >= len(df_result)]\n",
    "\n",
    "\n",
    "\n",
    "df_filtered_new = [v for _, v in df_filtered.groupby('event')]\n",
    "dictionary_event_startTime = np.empty(len(df_filtered_new), dtype=object) \n",
    "for idx, val in enumerate(df_filtered_new):\n",
    "    dictionary_event_startTime[idx] = val[\"startTime\"]\n",
    "\n",
    "listVal = df_filtered\n",
    "listVal\n",
    "\n",
    "columnNames = ['case', 'event', 'startTime', 'completeTime', 'AMOUNT_REQ', 'REG_DATE']\n",
    "\n",
    "listValSelected = listVal[columnNames]\n",
    "listValSelected_prediction = df_prediction[columnNames]\n",
    "listValSelected_prediction = listValSelected_prediction.values.astype('float32')\n",
    "listValDuration_prediction = df_prediction['duration']\n",
    "listValDuration_prediction = listValDuration_prediction.values.astype('float32')\n",
    "listValDuration = listVal['duration'].astype('float32')\n",
    "\n",
    "listValSelected = listValSelected.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = len(listValSelected[0])\n",
    "# split into samples\n",
    "\n",
    "\n",
    "n_features = 1\n",
    "X = listValSelected.reshape((listValSelected.shape[0], listValSelected.shape[1], n_features))\n",
    "y = listValDuration\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(n_steps, n_features), return_sequences=False, dropout=0.1, recurrent_dropout=0.1))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "# Dropout for regularization\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X, y, epochs=10, verbose=2, workers=-1)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = listValSelected_prediction\n",
    "\n",
    "x_input = x_input.reshape((x_input.shape[0], n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(x_input, verbose=2)\n",
    "lenVal_len = len(listValDuration_prediction) \n",
    "\n",
    "print(mean_absolute_error(listValDuration_prediction, yhat.flatten()[:lenVal_len])) # 286867030000.0 nanoseconds which is 5 minutes\n",
    "test_df[\"duration_prediction\"] = yhat.flatten()[:len(test_df)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "select = SelectKBest(k=3) # takes best 3 arguments \n",
    "z = select.fit_transform(listValSelected, listValDuration)\n",
    "filter = select.get_support()\n",
    "# 3 best features['case' 'event' 'AMOUNT_REQ'] for time\n",
    "print(np.extract(filter, columnNames))\n",
    "\n",
    "\n",
    "select = SelectKBest(k=3) # takes best 3 arguments for event\n",
    "z = select.fit_transform(X_train, Y_train)\n",
    "filter = select.get_support()\n",
    "print(np.extract(filter, event_columns)) # ['event' 'AMOUNT_REQ' 'org:resource']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network for event prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # import auxiliary library, typical idiom\n",
    "import pandas as pd  # import the Pandas library, typical idiom\n",
    "from numba import jit\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from tqdm.keras import TqdmCallback\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('export2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['case','startTime'])\n",
    "df = df.reset_index()\n",
    "#A function for determining the true next event for each event\n",
    "@jit(parallel = True)\n",
    "def calculator_nb(case, event):\n",
    "    res = np.empty(len(case), dtype=object)\n",
    "    idx = 0\n",
    "    for _ in case:\n",
    "        if (idx+1 >= len(case)):\n",
    "            break\n",
    "       \n",
    "        if (case[idx + 1] == case[idx]):\n",
    "            res[idx] = event[idx + 1]\n",
    "\n",
    "        idx+=1\n",
    "    return res\n",
    "\n",
    "df['next_event'] = calculator_nb(df['case'].values, df['event'].values)\n",
    "\n",
    "\n",
    "#A function for determining the true next event for each event\n",
    "@jit(parallel = True)\n",
    "def calculator_nb(case, startTime):\n",
    "    res = np.empty(len(case), dtype=object)\n",
    "    idx = 0\n",
    "    for _ in case:\n",
    "        if (idx+1 >= len(case)):\n",
    "            break\n",
    "       \n",
    "        if (case[idx + 1] == case[idx]):\n",
    "            res[idx] = startTime[idx + 1]\n",
    "        else:\n",
    "            res[idx] = startTime[idx]\n",
    "\n",
    "        idx+=1\n",
    "    return res\n",
    "\n",
    "df['completeTime'] = calculator_nb(df['case'].values, df['startTime'].values)\n",
    "df.at[2514265, 'completeTime'] = df.at[2514265, 'startTime']\n",
    "\n",
    "df['startTime'] =  pd.to_datetime(df['startTime'])\n",
    "df['completeTime'] =  pd.to_datetime(df['completeTime'])\n",
    "df['duration'] = df['completeTime'] - df['startTime']\n",
    "\n",
    "duration = df['duration']\n",
    "duration = duration / np.timedelta64(1, 's')\n",
    "df['duration'] = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index()\n",
    "validate = validate.reset_index()\n",
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepfeatures_OLS(df_name):\n",
    "    startTime = pd.to_datetime(df_name['startTime'])\n",
    "    \n",
    "    for i in range(len(startTime)):\n",
    "        startTime[i] = startTime[i].timestamp()\n",
    "        \n",
    "    startTime = np.array(startTime).reshape(-1,1)\n",
    "    \n",
    "    event = df_name['event'].to_numpy()\n",
    "    event = event.reshape(-1,1)\n",
    "    event = ordinal_encoder.fit_transform(event)\n",
    "    \n",
    "    #payment_actual0 = normalize(df_name,'payment_actual0')\n",
    "    #penalty_amount0 = normalize(df_name,'penalty_amount0')\n",
    "    #number_parcels = normalize(df_name,'number_parcels')\n",
    "    #area = normalize(df_name,'area')\n",
    "    payment_actual0 = df_name['payment_actual0'].to_numpy()\n",
    "    penalty_amount0 = df_name['penalty_amount0'].to_numpy()\n",
    "    number_parcels = df_name['number_parcels'].to_numpy()\n",
    "    area = df_name['area'].to_numpy()\n",
    "    \n",
    "    X = []\n",
    "    for i in range(len(event)):\n",
    "        current = startTime[i]\n",
    "        current = np.append(current, event[i])\n",
    "        current = np.append(current, payment_actual0[i])\n",
    "        current = np.append(current, penalty_amount0[i])\n",
    "        current = np.append(current, number_parcels[i])\n",
    "        current = np.append(current, area[i])\n",
    "        X.append(current)\n",
    "        \n",
    "    return np.array(X, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preplabels_OLS(df_name):\n",
    "    duration = df_name['duration'].to_numpy()\n",
    "    return np.array(duration, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prepfeatures_OLS(train)\n",
    "y = preplabels_OLS(train)\n",
    "huber = HuberRegressor().fit(X, y)\n",
    "X_test = prepfeatures_OLS(test)\n",
    "test['predicted'] = huber.predict(X_test)\n",
    "test['error'] = np.absolute(test['duration'] - test['predicted'])\n",
    "test['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df_name, col_name):\n",
    "    col_as_array = df_name[col_name].to_numpy()\n",
    "    col_as_array = np.where(col_as_array == 0, 0.5, col_as_array)\n",
    "    col_as_array_norm = np.log10(col_as_array)\n",
    "    mean = col_as_array_norm.mean()\n",
    "    stdev = col_as_array_norm.std()\n",
    "    epsilon = 0.01\n",
    "    return (col_as_array_norm - mean) / (stdev + epsilon)\n",
    "\n",
    "def prepfeatures(df_name):\n",
    "    event = df_name['event'].to_numpy()\n",
    "    event = event.reshape(-1,1)\n",
    "    event = ordinal_encoder.fit_transform(event)\n",
    "    \n",
    "    number_parcels = normalize(df_name,'number_parcels')\n",
    "    payment_actual0 = normalize(df_name,'payment_actual0')\n",
    "    area = normalize(df_name,'area')\n",
    "    cross_compliance = normalize(df_name,'cross_compliance')\n",
    "    penalty_amount0 = normalize(df_name,'penalty_amount0')\n",
    "    \n",
    "    features = []\n",
    "    for i in range(len(event)):\n",
    "        current = event[i]\n",
    "        current = np.append(current,number_parcels[i])\n",
    "        current = np.append(current,payment_actual0[i])\n",
    "        current = np.append(current,area[i])\n",
    "        current = np.append(current,cross_compliance[i])\n",
    "        current = np.append(current,penalty_amount0[i])\n",
    "        features.append(current)\n",
    "        \n",
    "    return np.array(features)\n",
    "\n",
    "def preplabels(df_name):\n",
    "    labels = df_name['next_event'].to_numpy()\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    \n",
    "    return np.array(labels)\n",
    "\n",
    "features = prepfeatures(train)\n",
    "labels = preplabels(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(6,)),\n",
    "    keras.layers.Dense(10, activation='relu'),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dense(20, activation='relu'),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(25, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(35, activation='relu'),\n",
    "    keras.layers.Dense(42, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(features,labels,epochs=5,verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = prepfeatures(test)\n",
    "labels_test = preplabels(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(features_test, labels_test, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
